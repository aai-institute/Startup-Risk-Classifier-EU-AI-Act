{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prohibited AI system</th>\n",
       "      <th>High-risk AI system under Annex I</th>\n",
       "      <th>High-risk AI system under Annex III</th>\n",
       "      <th>High-risk AI system with transparency obligations</th>\n",
       "      <th>System with transparency obligations</th>\n",
       "      <th>Low-risk AI system</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Total Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>#####AI Use Case:##### Total Store Simulation\\...</td>\n",
       "      <td></td>\n",
       "      <td>Risk Classification Counts:\\nProhibited AI sys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>#####AI Use Case:##### Intelligent Visual Insp...</td>\n",
       "      <td></td>\n",
       "      <td>Risk Classification Counts:\\nProhibited AI sys...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prohibited AI system High-risk AI system under Annex I  \\\n",
       "0                                                          \n",
       "1                                                          \n",
       "\n",
       "  High-risk AI system under Annex III  \\\n",
       "0                                       \n",
       "1                                       \n",
       "\n",
       "  High-risk AI system with transparency obligations  \\\n",
       "0                                                     \n",
       "1                                                     \n",
       "\n",
       "  System with transparency obligations  \\\n",
       "0                                        \n",
       "1                                        \n",
       "\n",
       "                                  Low-risk AI system Unknown  \\\n",
       "0  #####AI Use Case:##### Total Store Simulation\\...           \n",
       "1  #####AI Use Case:##### Intelligent Visual Insp...           \n",
       "\n",
       "                                        Total Counts  \n",
       "0  Risk Classification Counts:\\nProhibited AI sys...  \n",
       "1  Risk Classification Counts:\\nProhibited AI sys...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "def clean_text(text):\n",
    "    return re.sub(r'^[^\\w\\s]+', '', text).strip()\n",
    "\n",
    "def divide_classifications(text) -> dict:\n",
    "    if not isinstance(text, str) or text.strip().lower() == \"nan\":\n",
    "        return {}\n",
    "\n",
    "    expected_risk_classes = [\n",
    "        \"Prohibited AI system\",\n",
    "        \"High-risk AI system under Annex I\",\n",
    "        \"High-risk AI system under Annex III\",\n",
    "        \"High-risk AI system with transparency obligations\",\n",
    "        \"System with transparency obligations\",\n",
    "        \"Low-risk AI system\"\n",
    "    ]\n",
    "\n",
    "    use_case_dict = defaultdict(list)\n",
    "\n",
    "    # Split each block using the end marker\n",
    "    use_case_blocks = re.split(r\"#+END OF CLASSIFICATION#+\", text)\n",
    "\n",
    "    for block in use_case_blocks:\n",
    "        if not block.strip():\n",
    "            continue\n",
    "\n",
    "        use_case = re.search(r\"AI Use Case:\\s*(.*?)\\n\", block)\n",
    "        description = re.search(r\"Use Case Description:\\s*(.*?)(?=\\n[A-Z][a-z]+:|\\nRisk Classification:)\", block, re.DOTALL)\n",
    "        risk = re.search(r\"Risk Classification:\\s*(.*?)\\n\", block)\n",
    "        reason = re.search(r\"Reason:\\s*(.*?)(?=Requires Additional Information:)\", block, re.DOTALL)\n",
    "        additional_info = re.search(r\"Requires Additional Information:\\s*(.*)\", block)\n",
    "        what_additional_info = re.search(r\"What additional Information:\\s*(.*?)(?=\\nModel Distribution:|\\n$)\", block, re.DOTALL)\n",
    "        model_distribution = re.search(r\"Model Distribution:\\s*(.*?)(?=\\nChosen Model:|\\Z)\", block, re.DOTALL)\n",
    "        chosen_model = re.search(r\"Chosen Model:\\s*(.*?)\\n\", block)\n",
    "\n",
    "        risk_classification = clean_text(risk.group(1)) if risk else \"Unknown\"\n",
    "\n",
    "        use_case_data = f\"#####AI Use Case:##### {clean_text(use_case.group(1)) if use_case else 'Unknown'}\\n\"\n",
    "        use_case_data += f\"#####Use Case Description:##### {clean_text(description.group(1)) if description else 'Missing Description'}\\n\"\n",
    "        use_case_data += f\"#####Risk Classification:##### {risk_classification}\\n\"\n",
    "        use_case_data += f\"#####Reason:##### {clean_text(reason.group(1)) if reason else 'Missing Reason'}\\n\"\n",
    "\n",
    "        requires_additional_info = clean_text(additional_info.group(1)) if additional_info else 'Unknown'\n",
    "        what_additional_info_text = what_additional_info.group(1).strip() if what_additional_info else ''\n",
    "        if requires_additional_info.lower() == \"no\":\n",
    "            what_additional_info_text = \"\"\n",
    "\n",
    "        use_case_data += f\"#####Requires Additional Information:##### {requires_additional_info}\\n\"\n",
    "        use_case_data += f\"#####What additional Information:##### {what_additional_info_text}\\n\"\n",
    "\n",
    "        if model_distribution:\n",
    "            use_case_data += f\"#####Model Distribution:#####\\n{model_distribution.group(1).strip()}\\n\"\n",
    "\n",
    "        if chosen_model:\n",
    "            use_case_data += f\"#####Chosen Model:##### {clean_text(chosen_model.group(1))}\\n\"\n",
    "\n",
    "        if risk_classification in expected_risk_classes:\n",
    "            use_case_dict[risk_classification].append(use_case_data.strip())\n",
    "        else:\n",
    "            use_case_dict[\"Unknown\"].append(use_case_data.strip())\n",
    "\n",
    "    # Combine results into an ordered dictionary\n",
    "    ordered_use_case_dict = {risk: \"\\n\\n\\n\\n\\n\\n\".join(use_case_dict.get(risk, [])) for risk in expected_risk_classes}\n",
    "    ordered_use_case_dict[\"Unknown\"] = \"\\n\\n\\n\\n\\n\\n\".join(use_case_dict.get(\"Unknown\", []))\n",
    "\n",
    "    # Add counts\n",
    "    counts = {risk: len(use_case_dict[risk]) for risk in expected_risk_classes}\n",
    "    totals_string = \"Risk Classification Counts:\\n\" + \"\\n\".join([f\"{k}: {v}\" for k, v in counts.items()])\n",
    "    ordered_use_case_dict[\"Total Counts\"] = totals_string\n",
    "\n",
    "    # Handle case where all counts are 0\n",
    "    if all(v == 0 for v in counts.values()):\n",
    "        ordered_use_case_dict = {k: \"No Classification Found\" for k in ordered_use_case_dict.keys()}\n",
    "\n",
    "    return ordered_use_case_dict\n",
    "\n",
    "\n",
    "# Load Excel file\n",
    "df = pd.read_csv(\"combined_with_missing.csv\")\n",
    "\n",
    "# Apply classification function\n",
    "divided_data = df['Generated Text'].astype(str).apply(divide_classifications)\n",
    "\n",
    "# Expand into DataFrame\n",
    "expanded_df = pd.DataFrame(list(divided_data))\n",
    "expanded_df.to_csv(\"Structured Results.csv\", index=False)\n",
    "\n",
    "# Display first few rows\n",
    "expanded_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_response(text):\n",
    "    match = re.search(r'\\b(Yes|No)\\b', text, re.IGNORECASE)\n",
    "    \n",
    "    if match:\n",
    "        response = match.group(0)\n",
    "        if response.lower() == \"yes\":\n",
    "            reason_match = re.search(r'Yes\\s*[-â€“]?\\s*[^a-zA-Z]*([A-Za-z].*)', text, re.IGNORECASE | re.DOTALL)\n",
    "            reason = reason_match.group(1).strip() if reason_match else \"\"\n",
    "            return response, reason\n",
    "        else:\n",
    "            return response, \"\"\n",
    "    \n",
    "    return None, \"\"\n",
    "\n",
    "# # Example usage\n",
    "# text = \"Yes. - Additional information about the specific defects being detected and the products being inspected would help determine if the system might alternatively be classified under Annex I. If the system is used for products covered by Union harmonization laws listed in Annex I that require third-party conformity assessment, it could be classified as a High-risk AI system under Annex I instead.\"\n",
    "\n",
    "# requires_additonal_info, what_other_info = extract_response(text)\n",
    "# print(\"requires_additonal_info:\", requires_additonal_info)\n",
    "# print(\"what_other_info:\", what_other_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file saved as ai_risk_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# List of columns to process in priority order (highest risk first)\n",
    "columns_to_process = [\n",
    "    \"Prohibited AI system\",\n",
    "    \"High-risk AI system under Annex I\",\n",
    "    \"High-risk AI system under Annex III\",\n",
    "    \"High-risk AI system with transparency obligations\",\n",
    "    \"System with transparency obligations\",\n",
    "    \"Low-risk AI system\"\n",
    "]\n",
    "\n",
    "# Function to extract structured AI system data for a single row\n",
    "def process_row(row):\n",
    "    ai_systems_dict = {}\n",
    "\n",
    "    for column in columns_to_process:\n",
    "        if column in row and pd.notna(row[column]):\n",
    "            ai_systems_dict[column] = {\n",
    "                \"requires-additional-info\": {\n",
    "                    \"no\": [],\n",
    "                    \"yes\": []\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Split use cases using \\n\\n\\n\\n\\n\\n\n",
    "            use_case_blocks = re.findall(r\"#####AI Use Case:#####(.*?)(?=#####AI Use Case:#####|$)\", row[column], re.DOTALL)\n",
    "\n",
    "            for block in use_case_blocks:\n",
    "                block = block.strip()\n",
    "\n",
    "                # Extract fields\n",
    "                use_case = re.search(r\"^(.+)\", block)\n",
    "                description = re.search(r\"#####Use Case Description:#####\\s*(.*?)\\n\", block, re.DOTALL)\n",
    "                risk = re.search(r\"#####Risk Classification:#####\\s*(.*?)\\n\", block)\n",
    "                reason = re.search(r\"#####Reason:#####\\s*(.*?)\\n(?:#####Requires Additional Information:#####|$)\", block, re.DOTALL)\n",
    "                additional_info = re.search(r\"#####Requires Additional Information:#####\\s*(.*?)(?:\\n|$)\", block)\n",
    "                what_additional_info = re.search(r\"#####What additional Information:#####\\s*(.*?)(?=\\n#####|$)\", block, re.DOTALL)\n",
    "                model_distribution = re.search(r\"#####Model Distribution:#####\\s*(.*?)(?=\\n#####|$)\", block, re.DOTALL)\n",
    "                chosen_model = re.search(r\"#####Chosen Model:#####\\s*(.*?)(?=\\n|$)\", block)\n",
    "\n",
    "                # Assign values\n",
    "                use_case = use_case.group(1).strip() if use_case else None\n",
    "                description = description.group(1).strip() if description else None\n",
    "                risk = risk.group(1).strip() if risk else None\n",
    "                reason = reason.group(1).strip() if reason else None\n",
    "                additional_info = additional_info.group(1).strip() if additional_info else \"No\"\n",
    "                what_additional_info = what_additional_info.group(1).strip() if what_additional_info else \"\"\n",
    "                model_distribution = model_distribution.group(1).strip() if model_distribution else \"\"\n",
    "                chosen_model = chosen_model.group(1).strip() if chosen_model else \"\"\n",
    "\n",
    "                # Ensure what_additional_info is empty if requires_additional_info is 'No'\n",
    "                if additional_info.lower() == \"no\":\n",
    "                    what_additional_info = \"\"\n",
    "\n",
    "                # Determine category (\"no\" first, then \"yes\")\n",
    "                category = \"no\" if additional_info.lower() == \"no\" else \"yes\"\n",
    "\n",
    "                # Append to dictionary\n",
    "                ai_systems_dict[column][\"requires-additional-info\"][category].append({\n",
    "                    \"AI Use Case\": use_case,\n",
    "                    \"Use Case Description\": description,\n",
    "                    \"Risk Classification\": risk,\n",
    "                    \"Reason\": reason,\n",
    "                    \"Requires Additional Information\": additional_info,\n",
    "                    \"What Additional Information\": what_additional_info,\n",
    "                    \"Model Distribution\": model_distribution,\n",
    "                    \"Chosen Model\": chosen_model\n",
    "                })\n",
    "\n",
    "    return ai_systems_dict\n",
    "\n",
    "# Function to find the highest-risk use case for a single row\n",
    "def find_highest_risk_use_case(ai_dict):\n",
    "    for column in columns_to_process:  # Follow priority order\n",
    "        if column in ai_dict:\n",
    "            for priority in [\"no\", \"yes\"]:  # Prioritize \"no\" first\n",
    "                use_cases = ai_dict[column][\"requires-additional-info\"][priority]\n",
    "                if use_cases:  # Return the first available use case\n",
    "                    return {\"Category\": column, \"Use Case\": use_cases[0]}\n",
    "    return None  # If no use case is found\n",
    "\n",
    "# Process each row and store results\n",
    "json_outputs = []\n",
    "highest_risk_full_data = []\n",
    "\n",
    "highest_use_case_strings = []\n",
    "highest_risk_classifications = []\n",
    "requires_additonal_infos = []\n",
    "what_additional_infos = []\n",
    "\n",
    "for _, row in expanded_df.iterrows():\n",
    "    ai_data = process_row(row)\n",
    "    highest_risk = find_highest_risk_use_case(ai_data)\n",
    "\n",
    "    if highest_risk is not None and isinstance(highest_risk, dict):\n",
    "        highest_risk_classification = highest_risk['Use Case']['Risk Classification']\n",
    "        highest_use_case_string = \"\"\n",
    "        requires_additonal_info_full_string = highest_risk['Use Case']['Requires Additional Information']\n",
    "        what_additional_info_full_string = highest_risk['Use Case'].get(\"What Additional Information\", \"\")\n",
    "        \n",
    "        if requires_additonal_info_full_string.lower() == \"no\":\n",
    "            what_additional_info_full_string = \"\"\n",
    "        \n",
    "        for key, value in highest_risk['Use Case'].items():\n",
    "            highest_use_case_string += f\"#####{key}:##### {value}\\n\"\n",
    "        \n",
    "        highest_use_case_string = highest_use_case_string.rstrip('\\n#####')\n",
    "\n",
    "    else:\n",
    "        highest_risk_classification = \"PARSE ERROR - No Classification found.\"\n",
    "        highest_use_case_string = \"PARSE ERROR - No Classification found.\"\n",
    "        requires_additonal_info_full_string = \"PARSE ERROR - No Classification found.\"\n",
    "        what_additional_info_full_string = \"PARSE ERROR - No Classification found.\"\n",
    "\n",
    "    json_outputs.append(json.dumps(ai_data, indent=4))\n",
    "    highest_risk_full_data.append(json.dumps(highest_risk, indent=4) if highest_risk else \"No Classification found.\")\n",
    "    highest_use_case_strings.append(highest_use_case_string)\n",
    "    highest_risk_classifications.append(highest_risk_classification)\n",
    "    requires_additonal_infos.append(requires_additonal_info_full_string)\n",
    "    what_additional_infos.append(what_additional_info_full_string)\n",
    "\n",
    "# Add results to the dataframe\n",
    "expanded_df[\"json_output\"] = json_outputs\n",
    "expanded_df[\"highest_risk_use_case\"] = highest_risk_full_data\n",
    "expanded_df[\"highest_use_case_string\"] = highest_use_case_strings\n",
    "expanded_df[\"highest_risk_classification\"] = highest_risk_classifications\n",
    "expanded_df[\"requires_additional_info\"] = requires_additonal_infos\n",
    "expanded_df[\"what_additional_info\"] = what_additional_infos\n",
    "\n",
    "# Save to Excel\n",
    "output_file = \"ai_risk_analysis.csv\"\n",
    "expanded_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Excel file saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum cell length: 47817\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def max_cell_length_in_csv(file_path):\n",
    "    max_length = 0\n",
    "    with open(file_path, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            for cell in row:\n",
    "                cell_length = len(cell)\n",
    "                if cell_length > max_length:\n",
    "                    max_length = cell_length\n",
    "    return max_length\n",
    "\n",
    "# Example usage\n",
    "file_path = 'Structured Results.csv'  # Replace with your actual file path\n",
    "print(\"Maximum cell length:\", max_cell_length_in_csv(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Structured Results.csv\")\n",
    "# print(df.columns)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Row {index}:\")\n",
    "    for column in df.columns:\n",
    "        print(f\"{column}: {row[column]}\")\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    if index == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
