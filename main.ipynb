{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from urllib.parse import urlparse\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "def find_elements_by_xpath(xpath):\n",
    "    try:\n",
    "        elements = driver.find_elements(By.XPATH, xpath)\n",
    "        return elements\n",
    "    except NoSuchElementException:\n",
    "        print(f\"Element with XPath {xpath} not found.\")\n",
    "        return []\n",
    "    except Exception as e:  \n",
    "        print(f\"Unexpected error on XPath {xpath}. Reason: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty\n"
     ]
    }
   ],
   "source": [
    "if []:\n",
    "    print(\"Not empty\")\n",
    "else:\n",
    "    print(\"Empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://https://www.google.com\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.google.com\"\n",
    "string = f\"https://{url}\"\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, urlunparse\n",
    "\n",
    "def clean_link(url):\n",
    "        parsed_url = urlparse(url)\n",
    "        print(parsed_url)\n",
    "        # Determine if the path should have a trailing slash based on whether it looks like a directory\n",
    "        if parsed_url.path and not parsed_url.path.endswith('/'):\n",
    "            # Check if the path has no extension, meaning it's likely a directory\n",
    "            if '.' not in parsed_url.path.split('/')[-1]:\n",
    "                path_with_slash = parsed_url.path + '/'\n",
    "            else:\n",
    "                path_with_slash = parsed_url.path\n",
    "        else:\n",
    "            path_with_slash = parsed_url.path\n",
    "        \n",
    "        # Reconstruct URL without query parameters and fragments\n",
    "        cleaned_url = f\"{parsed_url.scheme}://{parsed_url.netloc}{path_with_slash}\"\n",
    "        return cleaned_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParseResult(scheme='', netloc='', path='google.com/file.html', params='', query='', fragment='')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'://google.com/file.html'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_link(\"google.com/file.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original URL: https://www.example.com\n",
      "Base Domain: www.example.com\n",
      "Cleaned URL: https://www.example.com\n",
      "\n",
      "Original URL: https://www.example.com/path\n",
      "Base Domain: www.example.com\n",
      "Cleaned URL: https://www.example.com/path\n",
      "\n",
      "Original URL: https://www.example.com/path/\n",
      "Base Domain: www.example.com\n",
      "Cleaned URL: https://www.example.com/path/\n",
      "\n",
      "Original URL: https://www.example.com/path/file.html\n",
      "Base Domain: www.example.com\n",
      "Cleaned URL: https://www.example.com/path/file.html\n",
      "\n",
      "Original URL: https://www.example.com/path/file.html?q=123#section1\n",
      "Base Domain: www.example.com\n",
      "Cleaned URL: https://www.example.com/path/file.html\n",
      "\n",
      "Original URL: https://www.example.com/path/file.html?q=123\n",
      "Base Domain: www.example.com\n",
      "Cleaned URL: https://www.example.com/path/file.html\n",
      "\n",
      "Original URL: https://www.example.com/path/file.html#section1\n",
      "Base Domain: www.example.com\n",
      "Cleaned URL: https://www.example.com/path/file.html\n",
      "\n",
      "Original URL: https://www.example.com/path/file\n",
      "Base Domain: www.example.com\n",
      "Cleaned URL: https://www.example.com/path/file\n",
      "\n",
      "Original URL: https://www.example.com/path/file/\n",
      "Base Domain: www.example.com\n",
      "Cleaned URL: https://www.example.com/path/file/\n",
      "\n",
      "Original URL: https://www.example.com/path/file/?q=123#section1\n",
      "Base Domain: www.example.com\n",
      "Cleaned URL: https://www.example.com/path/file/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parse the URL\n",
    "parsed_url = urlparse('https://www.google.com/file.html/?q=123#section1')\n",
    "# Examples of URLs to parse and clean\n",
    "urls = [\n",
    "    'https://www.example.com',\n",
    "    'https://www.example.com/path',\n",
    "    'https://www.example.com/path/',\n",
    "    'https://www.example.com/path/file.html',\n",
    "    'https://www.example.com/path/file.html?q=123#section1',\n",
    "    'https://www.example.com/path/file.html?q=123',\n",
    "    'https://www.example.com/path/file.html#section1',\n",
    "    'https://www.example.com/path/file',\n",
    "    'https://www.example.com/path/file/',\n",
    "    'https://www.example.com/path/file/?q=123#section1'\n",
    "]\n",
    "\n",
    "# Additional URLs to test base domain extraction\n",
    "additional_urls = [\n",
    "    'https://sub.example.com/path/file.html',\n",
    "    'http://example.com',\n",
    "    'https://example.co.uk/path/file',\n",
    "    'ftp://example.com/resource',\n",
    "    'https://www.example.com:8080/path/file',\n",
    "    'https://example.com/path/file.html?q=123#section1',\n",
    "    'https://example.com/path/file.html?q=123',\n",
    "    'https://example.com/path/file.html#section1',\n",
    "    'https://example.com/path/file',\n",
    "    'https://example.com/path/file/'\n",
    "]\n",
    "\n",
    "# Parse and clean each URL\n",
    "for url in urls:\n",
    "    parsed_url = urlparse(url)\n",
    "    cleaned_url = urlunparse((parsed_url.scheme, parsed_url.netloc, parsed_url.path, '', '', ''))\n",
    "    print(f\"Original URL: {url}\")\n",
    "    print(f\"Base Domain: {parsed_url.netloc}\")\n",
    "\n",
    "    print(f\"Cleaned URL: {cleaned_url}\\n\")\n",
    "\n",
    "# # Rebuild the cleaned URL (keep path as-is, drop query and fragment)\n",
    "# cleaned_url = urlunparse((parsed_url.scheme, parsed_url.netloc, parsed_url.path, '', '', ''))\n",
    "# cleaned_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Accept' == 'accept'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accept',\n",
       " 'agree',\n",
       " 'got it',\n",
       " 'continue',\n",
       " 'ok',\n",
       " 'i accept',\n",
       " 'i agree',\n",
       " 'allow',\n",
       " 'accept cookies',\n",
       " 'yes, i agree',\n",
       " 'akzeptieren',\n",
       " 'einverstanden',\n",
       " 'zustimmen',\n",
       " 'fortfahren',\n",
       " 'ablehnen',\n",
       " 'alle ausw채hlen',\n",
       " 'ausw채hlen',\n",
       " 'alle akzeptieren',\n",
       " 'alles akzeptieren',\n",
       " 'alle ablehnen',\n",
       " 'zustimmen und weiter',\n",
       " 'alle zulassen']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cookie_button_labels = [\"Accept\", \"Agree\", \"Got it\", \"Continue\", \"OK\", \"I Accept\", \"I Agree\", \"Allow\", \"Accept Cookies\", \"Yes, I Agree\", \"Akzeptieren\", \"Einverstanden\", \"Zustimmen\", \"Fortfahren\", \"Ablehnen\", \"Alle ausw채hlen\", \"ausw채hlen\", \"Alle akzeptieren\", \"Alles akzeptieren\", \"Alle ablehnen\", \"Zustimmen und weiter\", \"Alle zulassen\"]\n",
    "\n",
    "cookie_button_labels = [x.lower() for x in cookie_button_labels]\n",
    "\n",
    "cookie_button_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "custom-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
